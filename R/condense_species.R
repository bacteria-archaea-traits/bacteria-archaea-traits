# Condense to one row per species data
# Uses "combined_data.csv" generated by the script "combine.R"

print("Condensing data to species level...", quote = FALSE)

#Load data base don the phylogeny settings
if(exists("CONSTANT_BASE_PHYLOGENY") & !is.na(CONSTANT_BASE_PHYLOGENY) & CONSTANT_BASE_PHYLOGENY != "") {
  file <- sprintf("output/condensed_traits_%s.csv",CONSTANT_BASE_PHYLOGENY)
  if(CONSTANT_BASE_PHYLOGENY == "GTDB" & CONSTANT_FILL_GTDB_WITH_NCBI) {
    file <- unlist(strsplit(file, ".", fixed = TRUE))
    file <- sprintf("%s[NCBI_fill].csv",file[1])
  }
  df <- read.csv(file)
} else {
  stop("No phylogeny chosen. Please set base phylogeny in settings to either NCBI or GTDB")
}

# Data removal (exclude if required)
############################################################

# Remove all species with "sp" and "sp." in them
if(CONSTANT_BASE_PHYLOGENY == "NCBI") {
  df <- filter(df, !grepl("+[[:space:]]+sp[.]+", species))
}

# Remove size values > 100um. 
# While some rare microbes are very large, most data with size values >100um
# have been found to be either length of filaments (multiple individual cells) 
# or due to errors in unit input which has resulted in conversion to very large values
# (i.e. 5mm -> 5000um, where originally mm should have been um)
df[!is.na(df$d1_lo) & df$d1_lo > 100, "d1_lo"] <- NA # total of 16 as per 21/03/2019
df[!is.na(df$d1_up) & df$d1_up > 100, "d1_up"] <- NA # total of 4
df[!is.na(df$d2_lo) & df$d2_lo > 100, "d2_lo"] <- NA # total of 16
df[!is.na(df$d2_up) & df$d2_up > 100, "d2_up"] <- NA # total of 4

############################################################


#Create list of unique species
#un <- unique(df$species)

# Get all species represented by more than one row
multi <- unique(df[duplicated(df$species),"species"])

#Store all species represented by only one entry (final data)
#This is the beginning of the final data frame (df_final)
#df_final <- df[!(df$species %in% multi),]

df_final <- df


# Add columns

df_final[,paste(CONSTANT_CATEGORICAL_DATA_COLUMNS, ".count", sep="")] <- NA
df_final[,paste(CONSTANT_CATEGORICAL_DATA_COLUMNS, ".prop", sep="")] <- NA
df_final[,paste(CONSTANT_CONTINOUS_DATA_COLUMNS, ".count", sep="")] <- NA
df_final[,paste(CONSTANT_CONTINOUS_DATA_COLUMNS, ".stdev", sep="")] <- NA

# For all single row species fill in base statistics

# Categorical variables are saved with the number of values (for selected word) and 
# the proportional representation of this word amongst all entries for this species and variable
# For species represented by one row only, this means count = 1 and proportion = 100%


#1) First fill all fields assuming data exists

df_final[!(df_final$species %in% multi),names(df_final[,grepl(".count",names(df_final))])] <- 1
df_final[!(df_final$species %in% multi),names(df_final[,grepl(".prop",names(df_final))])] <- 100
df_final[!(df_final$species %in% multi),names(df_final[,grepl(".stdev",names(df_final))])] <- 0

#2) Remove cases where data does not exist

for(i in 1:length(CONSTANT_ALL_DATA_COLUMNS)) {
  trait <- CONSTANT_ALL_DATA_COLUMNS[i]
  
  #Define count column
  trait_count <- match(sprintf("%s.count",trait),names(df_final))
  
  #Get stdev or prop column depending on data type
  if(trait %in% CONSTANT_CATEGORICAL_DATA_COLUMNS) {
    trait_val <- match(sprintf("%s.prop",trait),names(df_final))
  } else {
    trait_val <- match(sprintf("%s.stdev",trait),names(df_final))
  }
  
  #Go through all single row species and remove inserted counts where no trait information
  df_final[!(df_final$species %in% multi) & is.na(df_final[,trait]),trait_count] <- 0
  df_final[!(df_final$species %in% multi) & is.na(df_final[,trait]), trait_val] <- NA
}
 

# Concatenate all data sources for each species
tmp <- df_final %>% group_by(species_tax_id) %>% 
  filter(!duplicated(data_source)) %>% 
  mutate(new_source = paste0(data_source, collapse = ", ")) %>% 
  filter(!duplicated(species_tax_id)) %>%
  select(species_tax_id,new_source) 
# Attach new source column to original
df_final <- df_final %>% left_join(tmp, by = "species_tax_id")       
# Remove old data source column
df_final <- subset(df_final,select = -c(data_source))
# Rename new data source column
colnames(df_final)[which(names(df_final) == "new_source")] <- "data_source"

# Concatenate all references for each species
tmp <- df_final %>% group_by(species_tax_id) %>% 
  filter(!is.na(ref_id)) %>% 
  summarise(ref_ids = paste0(unique(ref_id), collapse=", "))
# Attach new ref id column to original
df_final <- df_final %>% left_join(tmp, by = "species_tax_id")       
# Remove old ref id column
df_final <- subset(df_final,select = -c(ref_id))
# Rename new ref id column
colnames(df_final)[which(names(df_final) == "ref_ids")] <- "ref_id"

# Get all data of species represented by multiple entries for processing
process <- df_final[df_final$species %in% multi,]

# Restrict df_final to only single row species 
# - the rest will be added after processing
df_final <- df_final[!(df_final$species %in% multi),]

# Prepare multi-row species data

# Get one entry for each remaining species that will be processed below
multi <- process %>% group_by(species_tax_id) %>% 
  sample_n(1)

# Because we may be averaging over several organisms from different studies/sources, we reset 
# tax_id, data_source and original name as well as all data columns 
multi[,c("tax_id","org_name",CONSTANT_ALL_DATA_COLUMNS)] <- NA

# Bind one row for each species to the final data frame 
# - the data for these species will be updated one at a time below
df_final <- df_final %>% bind_rows(multi)

rm(tmp,multi)


########################################
# Process traits for multi row species #
########################################

# In below steps categorical, continuous and isolation source data is condensed
# For categorical and continuous data a designated function is used to process 
# all relevant columns (defined in settings)
# Note: the categorical condensation follows the rules outlined in Madin et al.

# Condense general categorical traits per species

for(i in 1:length(CONSTANT_GENERAL_CATEGORICAL_PROCESSING)) {
  print(sprintf("Condensing %s by dominant [>%s]",CONSTANT_GENERAL_CATEGORICAL_PROCESSING[i],CONSTANT_DOMINANT_TRAIT_PROPORTION))
  df_final <- condense_categorical_traits(df_final,process,CONSTANT_DOMINANT_TRAIT_PROPORTION,CONSTANT_GENERAL_CATEGORICAL_PROCESSING[i],CONSTANT_DOMINANT_TRAIT_PRIORITISE) 
}

# Condense continuous traits per species

for(i in 1:length(CONSTANT_CONTINOUS_DATA_COLUMNS)) {
  print(sprintf("Condensing %s as mean and stdev",CONSTANT_CONTINOUS_DATA_COLUMNS[i]))
  df_final <- condense_continous_traits(df_final,process,CONSTANT_CONTINOUS_DATA_COLUMNS[i]) 
}

# Condensene concatenated data where all unique data points are combined into one string
# (takes concatenated data and restructure it into a concatenated string of unique values)

for(i in 1:length(CONSTANT_DATA_COMMA_CONCATENATED)) {
  print(sprintf("Condensing %s to concatenated string",CONSTANT_DATA_COMMA_CONCATENATED[i]))
  df_final <- condense_concatenated_traits(df_final,process,CONSTANT_DATA_COMMA_CONCATENATED[i]) 
}


# condensen isolation_source per species
# This is done step wise from term 1 -> term 4

print("Condensing isolation source by species")

tmp <- process %>% group_by(species,isolation_source) %>% 
  filter(!is.na(isolation_source)) %>% 
  summarise(n = n())
# sum total data points per species
tmp2 <- tmp %>% group_by(species) %>% 
  summarise(total = sum(n))
# Join total count with per variable count
tmp3 <- inner_join(tmp,tmp2, by = "species")
# Calculate proportion and add to data frame
tmp3 <- tmp3 %>% mutate(prop = n / total * 100) %>%   
  mutate(prop = sprintf("%0.1f",prop))

tmp3$prop <- as.numeric(tmp3$prop)

# Get all results with 100% hit for a given environment and store in temporary results table
results <- tmp3 %>% filter(prop == 100)

## Deal with inconsistent data:

# Get remaining species
ruling <- tmp3 %>% filter(!(species %in% results$species))

#Separate isolation_source terms into columns
ruling <- ruling %>% separate(isolation_source, into = paste("h",1:4, sep = ""), sep = "_")

#Create table for holding resolved data
resolved <- ruling[!duplicated(ruling$species), "species"]

#Get term
# Process: 
#1. Group by species and term 1
#2. Count number of occurences for each term and species
#3. Only keep term with max number of occurences
#4. In case of ties, only keep first row (for term 1, else NA)

term <- ruling %>% group_by(species, h1) %>% 
  summarise(count = n()) %>% 
  na.omit() %>%
  filter(count == max(count)) %>% 
  filter(row_number() == 1)
  
#Add selected terms to resolved table
resolved <- resolved %>% inner_join(term[,1:2], by = "species")

###
# Process term2
###

term <- ruling %>% semi_join(resolved, by = c("species","h1")) %>%  
  group_by(species, h2) %>%
  summarise(count = n()) %>% 
  na.omit() %>%
  filter(count == max(count)) 

#Get all duplicated species (term could not be resolved)
remove <- term %>% group_by(species) %>% 
  summarise(count = n()) %>% 
  filter(count > 1) 

if(nrow(remove)) {
  print(sprintf("Term level 2 could not be resolved for %s species: data reduced.",nrow(remove)))
}

#Remove all species that could not be resolved at this level
term <- term[!(term$species %in% remove$species),]

#Add selected terms to resolved table
resolved <- resolved %>% left_join(term[,1:2], by = "species")

###
# Process term 3
###

term <- ruling %>% semi_join(resolved, by = c("species","h2")) %>%  
  group_by(species, h3) %>%
  summarise(count = n()) %>% 
  na.omit() %>%
  filter(count == max(count)) 

#Get all duplicated species (term could not be resolved)
remove <- term %>% group_by(species) %>% 
  summarise(count = n()) %>% 
  filter(count > 1) 

if(nrow(remove)) {
  print(sprintf("Term level 4 could not be resolved for %s species: data reduced.",nrow(remove)))
}

#Remove all species that could not be resolved at this level
term <- term[!(term$species %in% remove$species),]

#Add selected terms to resolved table
resolved <- resolved %>% left_join(term[,1:2], by = "species")

###
# process term 4
###

term <- ruling %>% semi_join(resolved, by = c("species","h3")) %>%  
  group_by(species, h4) %>%
  summarise(count = n()) %>% 
  na.omit() %>%
  filter(count == max(count)) 

#Get all duplicated species (term could not be resolved)
remove <- term %>% group_by(species) %>% 
  summarise(count = n()) %>% 
  filter(count > 1) 

if(nrow(remove)) {
  print(sprintf("Term level 4 could not be resolved for %s species: data reduced.",nrow(remove)))
}

#Remove all species that could not be resolved at this level
term <- term[!(term$species %in% remove$species),]

#Add selected terms to resolved table
resolved <- resolved %>% left_join(term[,1:2], by = "species")

#Combine terms to one string
#This is a coarse solution to avoid NA inclusion in paste

resolved$isolation_source <- NA

for(i in 1:nrow(resolved)) {
  
  term <- NA
  
  #Rebuild term
  if(!is.na(resolved$h1[i])) {
    if(!is.na(resolved$h2[i])) {
      if(!is.na(resolved$h3[i])) {
        if(!is.na(resolved$h4[i])) {
          term <- paste(resolved$h1[i], resolved$h2[i], resolved$h3[i], resolved$h4[i], sep = "_")
        } else {
          term <- paste(resolved$h1[i], resolved$h2[i], resolved$h3[i], sep = "_")
        }
      } else {
        term <- paste(resolved$h1[i], resolved$h2[i], sep = "_")
      }
    } else {
      term <- resolved$h1[i]
    }
  }
  
  if(is.na(term)) {
    term <- "unresolved"
  }
  resolved$isolation_source[i] <- term
  #print(sprintf("%s <- %s", resolved$species[i], term))
}

#Remove term columns
resolved <- subset(resolved,select = -c(h1,h2,h3,h4))
#Set unresolved isolation sources to NA
resolved[resolved$isolation_source == "unresolved","isolation_source"] <- NA

#Get count data for each species and selected term from original data frame
#Where a isolation_source term has been reduced to a common parent no counts are recorded at this stage (NA)
#This should be updated to include the sum of all recordswhere selected terms exists
resolved <- resolved %>% left_join(tmp3, by = c("species","isolation_source"))
resolved$prop <- as.numeric(resolved$prop)

#join rows of resolved isolation_sources to final results list
results <- results %>% bind_rows(resolved)
#Change isolation_source column name to avoid clash when merging with final data frame
colnames(results)[which(names(results) == "isolation_source")] <- "new_isolation_source"

# Add results to final data frame for each species
df_final <- df_final %>% left_join(results, by = "species")

# Move data from temperary columns to main columns
df_final[is.na(df_final$isolation_source),"isolation_source"] <- as.character(df_final$new_isolation_source[is.na(df_final$isolation_source)])
df_final[is.na(df_final$isolation_source.prop),"isolation_source.prop"] <- as.numeric(df_final$prop[is.na(df_final$isolation_source.prop)])
df_final[is.na(df_final$isolation_source.count),"isolation_source.count"] <- as.numeric(df_final$n[is.na(df_final$isolation_source.count)])

#Remove temporary columns
df_final <- subset(df_final, select = -c(new_isolation_source,n,total,prop))

#Clean up
rm(ruling,results,resolved,remove,process)


##############################
#Fill data from other sources#
##############################

print("Filling in missing data from Bergeys")

# Load Bergeys data
ber <- read.csv("output/prepared_data/bergeys.csv")

# Remove specific trait data from Candidatus species (uncultured)
# This is done here as bergeys is used as filler
# with no error correction on this data at this stage
if(exists("CONSTANT_REMOVE_FROM_CANDIDATUS") && length(CONSTANT_REMOVE_FROM_CANDIDATUS) > 0) {
  for(i in 1:length(CONSTANT_REMOVE_FROM_CANDIDATUS)) {
    if(CONSTANT_REMOVE_FROM_CANDIDATUS[i] %in% names(ber))
      ber[!is.na(ber$species_name) & ber$species_name %in% ber[grepl("Candidatus",ber$species_name),"species_name"], CONSTANT_REMOVE_FROM_CANDIDATUS[i]] <- NA
  }
}


# Add prefix to column names
names(ber) <- paste0("ber.", names(ber))

# Join bergeys by species
df_final <- df_final %>% left_join(ber, by = c("species_tax_id" = "ber.species_tax_id"))

# Transfer values from bergeys data columns to species with missing values

#Add count, prop and stdev for each data point (n = 1)

df_final$ber.added <- FALSE #Flag to identify where bergeys data has been added

fill_traits <- c("metabolism","d1_lo","d1_up","d2_lo","d2_up","doubling_h")

for(i in 1:length(fill_traits)) {
  
  org_trait <- fill_traits[i]
  ber_trait <- sprintf("ber.%s",org_trait)
  trait_count <- sprintf("%s.count", org_trait)
  
  #Add count to trait
  df_final[is.na(df_final[,org_trait]) & !is.na(df_final[,ber_trait]), trait_count] <- 1
  
  if(org_trait %in% CONSTANT_CATEGORICAL_DATA_COLUMNS) {
    trait_val <- sprintf("%s.prop", org_trait)
    df_final[is.na(df_final[,org_trait]) & !is.na(df_final[,ber_trait]), trait_val] <- 100
  } else {
    trait_val <- sprintf("%s.stdev", org_trait)
    df_final[is.na(df_final[,org_trait]) & !is.na(df_final[,ber_trait]), trait_val] <- 0
  }
  
  #Flag that bergeys data is added for this row
  df_final[is.na(df_final[,org_trait]) & !is.na(df_final[,ber_trait]), "ber.added"] <- TRUE
  #Add main data (this has to be done last)
  df_final[is.na(df_final[,org_trait]) & !is.na(df_final[,ber_trait]), org_trait] <- df_final[is.na(df_final[,org_trait]) & !is.na(df_final[,ber_trait]), ber_trait]

}


# Add bergeys to data_source column where ber.add == TRUE
df_final$data_source[df_final$ber.add == TRUE] <- sprintf("%s, %s",df_final$data_source[df_final$ber.add == TRUE],"bergeys")

# Remove bergeys columns
df_final <- df_final[, !grepl("ber.", names(df_final))]
rm(ber)


# Calculate temperature adjusted doubling times on any added growth rates (where doubling_h_norm isn't already calculated)
#Create temporary temperature column
df_final$tmp_tmp <- NA
df_final$tmp_tmp[is.na(df_final$doubling_h_norm)] <- df_final$growth_tmp[is.na(df_final$doubling_h_norm)]
df_final$tmp_tmp[is.na(df_final$tmp_tmp) & !is.na(df_final$optimum_tmp) & is.na(df_final$doubling_h_norm)] <- df_final$optimum_tmp[is.na(df_final$tmp_tmp) & !is.na(df_final$optimum_tmp) & is.na(df_final$doubling_h_norm)]

#Calculate rates for each row
df_final$doubling_h_norm[!is.na(df_final$doubling_h) & !is.na(df_final$tmp_tmp) & is.na(df_final$doubling_h_norm)] <- apply(df_final[!is.na(df_final$doubling_h) & !is.na(df_final$tmp_tmp) & is.na(df_final$doubling_h_norm), c("tmp_tmp","doubling_h")],1 , function(x) temp_adjust_doubling_h(x['doubling_h'], x['tmp_tmp'], CONSTANT_GROWTH_RATE_ADJUSTMENT_FINAL_TMP, CONSTANT_GROWTH_RATE_ADJUSTMENT_Q10))

#Remove temporary temperature column
df_final <- subset(df_final, select = -c(tmp_tmp))


#########################################
#Ensure coccus shaped cells (round) also# 
#have a length value (d2) if no length  #
#########################################

df_final$d2_lo[!is.na(df_final$cell_shape) & df_final$cell_shape == "coccus" & !is.na(df_final$d1_lo) & is.na(df_final$d2_lo)] <- as.double(df_final$d1_lo[!is.na(df_final$cell_shape) & df_final$cell_shape == "coccus" & !is.na(df_final$d1_lo) & is.na(df_final$d2_lo)])
df_final$d2_up[!is.na(df_final$cell_shape) & df_final$cell_shape == "coccus" & !is.na(df_final$d1_up) & is.na(df_final$d2_up)] <- as.double(df_final$d1_up[!is.na(df_final$cell_shape) & df_final$cell_shape == "coccus" & !is.na(df_final$d1_up) & is.na(df_final$d2_up)])


#########################
#Mark specific organisms#
#########################

# Add intracellular status based on curated list of organisms (1 = intracellular, NA = no information)

# #Load list
# intr <- read.csv("data/conversion_tables/intracellular_organisms.csv")
# df_final$intracellular <- NA
# 
# for(i in 1:nrow(intr)) {
#   
#   if(intr$phyl_level[i] == "order") {
#     df_final$intracellular[df_final$order == intr$name[i]] <- "1"
#   } else if (intr$phyl_level[i] == "genus") {
#     df_final$intracellular[df_final$genus == intr$name[i]] <- "1"
#   } else if (intr$phyl_level[i] == "species") {
#     df_final$intracellular[df_final$species == intr$name[i]] <- "1"
#   }
#   #print(sprintf("%s -> %s",intr$phyl_level[i],intr$name[i]))
# }
# 
# rm(intr)
# 
# ####
# 
# # Mark phototrophic organisms based on curated list of organisms (1 = phototroph, NA = no information)
# pho <- read.csv("data/conversion_tables/phototrophic_organisms.csv")
# df_final$phototroph <- NA
# 
# for(i in 1:nrow(pho)) {
#   
#   if(pho$phyl_level[i] == "order") {
#     df_final$phototroph[df_final$order == pho$name[i]] <- "1"
#   } else if (pho$phyl_level[i] == "genus") {
#     df_final$phototroph[df_final$genus == pho$name[i]] <- "1"
#   } else if (pho$phyl_level[i] == "phylum") {
#     df_final$phototroph[df_final$phylum == pho$name[i]] <- "1"
#   } else if (pho$phyl_level[i] == "species") {
#     df_final$phototroph[df_final$species == pho$name[i]] <- "1"
#   }
#   #print(sprintf("%s -> %s",pho$phyl_level[i], pho$name[i]))
# }
# 
# rm(pho)

###########################
# Remove all rows with    #
# no relevant information #
###########################

# Remove rows with no data
df_final <- df_final[rowSums(is.na(df_final[CONSTANT_ALL_DATA_COLUMNS])) != length(CONSTANT_ALL_DATA_COLUMNS), ]

# Finally, make absolutely sure no species are duplicated
df_final <- df_final[!duplicated(df_final$species),]


#############################
# Remove not-needed columns #
#############################

df_final <- subset(df_final, select = -c(tax_id,org_name))


#fill in zero counts where no data exists
for(i in 1:length(CONSTANT_ALL_DATA_COLUMNS)) {
  trait <- CONSTANT_ALL_DATA_COLUMNS[i]
  #Define count column
  trait_count <- sprintf("%s.count",trait)
  #Go through all single row species and remove inserted counts where no trait information
  df_final[is.na(df_final[,trait]), trait_count] <- 0
}

#######################
#Save final data frame#
#######################


#Save main data frame
file <- sprintf("output/condensed_species_%s.csv",CONSTANT_BASE_PHYLOGENY)
if(CONSTANT_BASE_PHYLOGENY == "GTDB" & CONSTANT_FILL_GTDB_WITH_NCBI) {
  file <- unlist(strsplit(file, ".", fixed = TRUE))
  file <- sprintf("%s[NCBI_fill].csv",file[1])
}

write.csv(df_final, file, row.names=FALSE)

print("Data processing complete.", quote = FALSE)